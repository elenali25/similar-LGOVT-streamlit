import streamlit as st
import pandas as pd
import numpy as np
import re
import altair as alt 
from pathlib import Path

# ***************************************************************
# 1. åŒºåŸŸç­‰çº§å®šä¹‰ä¸æŸ¥æ‰¾ (ä¿æŒä¸å˜)
# ***************************************************************

A_REGIONS_CORE = ['å¹¿ä¸œ', 'æµ™æ±Ÿ', 'åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³', 'æ±Ÿè‹', 'å®æ³¢', 'å¦é—¨', 'å¹¿å·']
C_REGIONS_CORE = ['äº‘å—', 'è´µå·', 'å†…è’™å¤', 'é»‘é¾™æ±Ÿ', 'å‰æ—', 'è¾½å®', 'å¤©æ´¥', 'è¥¿è—', 'æµ·å—', 'å¹¿è¥¿å£®æ—', 'é’æµ·']

def create_region_level(region):
    """ å®šä¹‰åŒºåŸŸä¿¡ç”¨ç­‰çº§ï¼šA (å¥½), B (ä¸­), C (å·®) """
    clean_region = region.replace('çœ', '').replace('å¸‚', '').replace('è‡ªæ²»åŒº', '').strip()
    
    if clean_region in A_REGIONS_CORE: 
        return 'A'
    elif clean_region in C_REGIONS_CORE:
        return 'C'
    else:
        return 'B'

def find_region_and_level(user_input_region, all_regions_data):
    """ æ ¹æ®ç”¨æˆ·è¾“å…¥æ¨¡ç³ŠåŒ¹é…çœä»½ï¼Œå¹¶è¿”å›è¯¥çœä»½çš„å…¨åå’ŒåŒºåŸŸç­‰çº§ã€‚"""
    if not user_input_region:
        return None, None
        
    clean_input = user_input_region.replace('çœ', '').replace('å¸‚', '').replace('è‡ªæ²»åŒº', '').strip()
    
    for full_region in all_regions_data:
        if full_region.replace('çœ', '').replace('å¸‚', '').replace('è‡ªæ²»åŒº', '').strip() == clean_input:
            level = create_region_level(full_region)
            return full_region, level
            
    for full_region in all_regions_data:
        clean_full_region = full_region.replace('è‡ªæ²»åŒº', '').replace('çœ', '').replace('å¸‚', '')
        if clean_input in clean_full_region:
            level = create_region_level(full_region)
            return full_region, level
            
    return None, None 

# ***************************************************************
# 2. æ•°æ®åŠ è½½ä¸é¢„å¤„ç† (ä¿æŒä¸å˜)
# ***************************************************************

@st.cache_data
def load_data(uploaded_file_or_path):
    """
    åŠ è½½ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ï¼Œå¹¶è¿›è¡Œæ—¥æœŸç­›é€‰å’Œæ•°æ®æ¸…æ´—ã€‚
    """
    # å…¼å®¹ UploadedFile ä¸æœ¬åœ°æ–‡ä»¶è·¯å¾„ä¸¤ç§æ¥æº
    filename = uploaded_file_or_path.name if hasattr(uploaded_file_or_path, 'name') else str(uploaded_file_or_path)
    st.info(f"æ­£åœ¨åŠ è½½æ–‡ä»¶: {Path(filename).name}...")

    try:
        file_src = uploaded_file_or_path if hasattr(uploaded_file_or_path, 'name') else filename
        if filename.endswith('.csv'):
            df = pd.read_csv(file_src)
        elif filename.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(file_src, sheet_name=0)
        else:
            st.error("é”™è¯¯ï¼šæ–‡ä»¶æ ¼å¼ä¸æ”¯æŒã€‚")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return pd.DataFrame()
        
    df.columns = df.columns.astype(str).str.strip() 
    if 'æ˜¯å¦å…ç¨' in df.columns:
        df.rename(columns={'æ˜¯å¦å…ç¨': 'æ˜¯å¦äº¤ç¨'}, inplace=True)
    
    for col in ['å‘è¡Œæ—¥æœŸ', 'å½“å‰æ—¥æœŸ']:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
        
    for col in ['å‰©ä½™å¹´é™', 'æ”¶ç›˜æ”¶ç›Šç‡', 'ä¼°å€¼', 'ç¥¨é¢', 'ä½™é¢', 'æˆäº¤é‡']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # ç¡®ä¿å…³é”®åˆ†ç±»å­—æ®µæ˜¯å­—ç¬¦ä¸²ç±»å‹
    for col in ['å€ºåˆ¸ä»£ç ', 'æ˜¯å¦äº¤ç¨', 'ä¸“é¡¹ä¸€èˆ¬', 'åŒºåŸŸ']:
        if col in df.columns:
            df[col] = df[col].astype(str).str.strip()

    if 'å½“å‰æ—¥æœŸ' not in df.columns:
        st.error("é”™è¯¯ï¼šæ•°æ®ä¸­ç¼ºå°‘ 'å½“å‰æ—¥æœŸ' åˆ—ï¼Œæ— æ³•è¿›è¡Œæœ€æ–°æ—¥æœŸç­›é€‰ã€‚")
        return pd.DataFrame()
        
    latest_date = df['å½“å‰æ—¥æœŸ'].max()
    unique_dates = df['å½“å‰æ—¥æœŸ'].dropna().unique()
    # ç­›é€‰æœ€è¿‘ 5 ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®ï¼Œä½œä¸ºç­›é€‰åŸºç¡€æ•°æ®æº
    recent_dates = pd.Series(unique_dates).sort_values(ascending=False).iloc[:5] 

    df_filtered = df[df['å½“å‰æ—¥æœŸ'].isin(recent_dates)].copy() 
    
    if df_filtered.empty:
        return pd.DataFrame()

    if 'åŒºåŸŸ' in df_filtered.columns:
        df_filtered['åŒºåŸŸç­‰çº§'] = df_filtered['åŒºåŸŸ'].apply(create_region_level)
    if 'å‘è¡Œæ—¥æœŸ' in df_filtered.columns:
        df_filtered['å‘è¡Œå¹´ä»½'] = df_filtered['å‘è¡Œæ—¥æœŸ'].dt.year
    
    st.sidebar.info(f"æ•°æ®å·²æŒ‰æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥è¿‡æ»¤ã€‚æœ€æ–°æ—¥æœŸï¼š{latest_date.strftime('%Y-%m-%d')}")
    
    # è¿”å›ç”¨äºç­›é€‰å’Œå¯è§†åŒ–çš„åŸºç¡€æ•°æ®æ¡†
    return df_filtered

# ***************************************************************
# 3. ç­›é€‰æ ¸å¿ƒå‡½æ•° (ä¿æŒä¸å˜)
# ***************************************************************

TOLERANCE_LEVELS = {
    0: {'name': 'æœ€ä¸¥æ ¼æ¡£', 'term_tol': 0.3, 'coupon_tol': 0.3, 'type_match': True},
    1: {'name': 'æ”¾æ¾ä¸€æ¡£', 'term_tol': 0.5, 'coupon_tol': 0.5, 'type_match': False},
    2: {'name': 'æ”¾æ¾äºŒæ¡£', 'term_tol': 0.7, 'coupon_tol': 0.7, 'type_match': False}
}

def find_matching_bonds_by_level(df: pd.DataFrame, target: dict, region_level: str, level: int):
    """ æ ¹æ®ç”¨æˆ·è¾“å…¥çš„å•ä¸ªç›®æ ‡å±æ€§å’ŒæŒ‡å®šçš„å…¬å·®ç­‰çº§è¿›è¡Œç­›é€‰ """
    
    config = TOLERANCE_LEVELS.get(level)
    if not config:
        return pd.DataFrame()

    df_filtered = df.copy()
    
    # 1. å‰©ä½™å¹´é™
    df_filtered = df_filtered[
        (df_filtered['å‰©ä½™å¹´é™'] >= (target['term'] - config['term_tol'])) & 
        (df_filtered['å‰©ä½™å¹´é™'] <= (target['term'] + config['term_tol']))
    ]

    # 2. ç¥¨é¢åˆ©ç‡
    df_filtered = df_filtered[
        (df_filtered['ç¥¨é¢'] >= (target['coupon'] - config['coupon_tol'])) & 
        (df_filtered['ç¥¨é¢'] <= (target['coupon'] + config['coupon_tol']))
    ]
    
    # 3. ä¸“é¡¹ä¸€èˆ¬
    if config['type_match']:
        df_filtered = df_filtered[df_filtered['ä¸“é¡¹ä¸€èˆ¬'] == target['bond_type']]
    
    # 4. åŒºåŸŸç»´åº¦
    if region_level:
        df_filtered = df_filtered[df_filtered['åŒºåŸŸç­‰çº§'] == region_level]
    
    # 5. å‘è¡Œå¹´ä»½
    issue_year_tol = 1
    df_filtered = df_filtered[
        (df_filtered['å‘è¡Œå¹´ä»½'] >= (target['issue_year'] - issue_year_tol)) & 
        (df_filtered['å‘è¡Œå¹´ä»½'] <= (target['issue_year'] + issue_year_tol))
    ]
    
    # 6. æ˜¯å¦äº¤ç¨
    df_filtered = df_filtered[df_filtered['æ˜¯å¦äº¤ç¨'] == target['tax_status']]
    
    if df_filtered.empty:
        return pd.DataFrame()
        
    return df_filtered


def find_matching_bonds_with_fallback(df: pd.DataFrame, target: dict, region_level: str):
    """ è‡ªåŠ¨å°è¯• 3 ä¸ªä¸åŒçº§åˆ«çš„æ¡ä»¶ï¼Œç›´åˆ°æ‰¾åˆ°ç›¸ä¼¼å€ºåˆ¸ """
    
    for level in range(3): 
        results = find_matching_bonds_by_level(df, target, region_level, level)
        if not results.empty:
            return results, level 
            
    return pd.DataFrame(), 3 

# ***************************************************************
# 4. Streamlit ä¸»åº”ç”¨ 
# ***************************************************************

def main():
    st.set_page_config(page_title="åœ°æ–¹å€ºå±æ€§åŒ¹é…ç­›é€‰å·¥å…·", layout="wide")
    st.title("åœ°æ–¹å€ºç›¸ä¼¼å±æ€§åˆ†çº§åŒ¹é…ç­›é€‰å·¥å…·")
    
    uploaded_file = st.sidebar.file_uploader(
        "è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ‚¨çš„åœ°æ–¹å€ºæ•°æ®æ–‡ä»¶ (.xlsx æˆ– .csv)", 
        type=["xlsx", "csv"]
    )
    
    df = pd.DataFrame()
    
    if uploaded_file is None:
        # å°è¯•ä½¿ç”¨ä»“åº“ä¸­çš„é»˜è®¤æ ·æœ¬æ•°æ®
        sample_path = Path(__file__).resolve().parent / "æ ·æœ¬æ•°æ®.xlsx"
        if sample_path.exists():
            st.info("æœªä¸Šä¼ æ–‡ä»¶ï¼Œå·²è‡ªåŠ¨åŠ è½½ä»“åº“ä¸­çš„é»˜è®¤æ ·æœ¬æ•°æ®ã€‚")
            df = load_data(str(sample_path))
        else:
            st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ‚¨çš„æ•°æ®æ–‡ä»¶å¼€å§‹å±æ€§ç­›é€‰ã€‚")
            st.sidebar.header("è¾“å…¥ç›®æ ‡å±æ€§")
            st.sidebar.warning("æ•°æ®æœªåŠ è½½")
            return
    
    # df æ˜¯åŒ…å«æœ€è¿‘ 5 ä¸ªäº¤æ˜“æ—¥æ•°æ®çš„åŸºç¡€æ•°æ®æ¡†
    if uploaded_file is not None:
        df = load_data(uploaded_file)
    if df.empty:
        return
    
    # --- ä¾§è¾¹æ ï¼šç›®æ ‡å±æ€§è¾“å…¥ ---
    st.sidebar.header("ğŸ¯ è¾“å…¥ç›®æ ‡åˆ¸çš„ 6 ä¸ªç­›é€‰å±æ€§")
    
    target_term = st.sidebar.number_input("ğŸ“… å‰©ä½™å¹´é™ (å¹´)", min_value=0.0, value=5.0, step=0.1, format='%.2f')
    target_coupon = st.sidebar.number_input("ğŸ·ï¸ ç¥¨é¢åˆ©ç‡ (%)", min_value=0.0, value=3.20, step=0.01, format='%.2f')
    target_type = st.sidebar.selectbox("ğŸ“„ ä¸“é¡¹/ä¸€èˆ¬ç±»å‹", options=df['ä¸“é¡¹ä¸€èˆ¬'].unique().tolist(), index=0)

    all_regions = df['åŒºåŸŸ'].unique().tolist()
    input_region = st.sidebar.text_input("ğŸŒ è¾“å…¥çœä»½å…³é”®è¯ (å¦‚: å®‰å¾½)", value="å®‰å¾½").strip()
    
    matched_region, region_level = find_region_and_level(input_region, all_regions)
    
    if matched_region:
        st.sidebar.success(f"åŒ¹é…åˆ°ï¼š{matched_region} (ç­‰çº§: {region_level})")
    else:
        st.sidebar.error("æœªæ‰¾åˆ°åŒ¹é…çš„çœä»½ï¼Œè¯·æ£€æŸ¥å…³é”®è¯ã€‚")
    
    target_issue_year = st.sidebar.slider("ğŸ—“ï¸ ç›®æ ‡å‘è¡Œå¹´ä»½ (å…¬å·®Â±1å¹´)", min_value=int(df['å‘è¡Œå¹´ä»½'].min()), max_value=int(df['å‘è¡Œå¹´ä»½'].max()), value=2023)
    target_tax = st.sidebar.selectbox("ğŸ§¾ æ˜¯å¦äº¤ç¨", options=df['æ˜¯å¦äº¤ç¨'].unique().tolist(), index=0)
    
    target_attributes = {
        'term': target_term,
        'coupon': target_coupon,
        'bond_type': target_type,
        'issue_year': target_issue_year,
        'tax_status': target_tax,
    }
    
    # --- æ ¸å¿ƒç­›é€‰é€»è¾‘ (ç”Ÿæˆç›¸ä¼¼åˆ¸åˆ—è¡¨) ---
    st.header("åŒ¹é…ç»“æœï¼šä¸ç›®æ ‡å±æ€§ç›¸è¿‘çš„å€ºåˆ¸")
    
    if not matched_region:
        st.warning("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æœ‰æ•ˆçš„çœä»½å…³é”®è¯ã€‚")
        return

    with st.spinner('æ­£åœ¨æ ¹æ®åˆ†çº§æ”¾æ¾æœºåˆ¶ç­›é€‰åŒ¹é…åˆ¸...'):
        # filtered_df: è¿™æ˜¯éœ€è¦å±•ç¤ºåœ¨è¡¨æ ¼ä¸­çš„ç›¸ä¼¼åˆ¸
        filtered_df, relaxation_level = find_matching_bonds_with_fallback(
            df, target_attributes, region_level
        )
        
    st.metric("ğŸ‰ åŒ¹é…åˆ°çš„å€ºåˆ¸æ•°é‡", filtered_df.shape[0])
    
    # çŠ¶æ€å’Œå…¬å·®æ˜¾ç¤º (ä¿æŒä¸å˜)
    if filtered_df.empty:
        st.error("ğŸ›‘ æ— æ³•æ‰¾åˆ°ç›¸ä¼¼åˆ¸ï¼Œå·²å°è¯•æ‰€æœ‰æ”¾æ¾æ¡£ä½ã€‚")
        st.warning(
            f"è¯·æ£€æŸ¥æ ¸å¿ƒæ¡ä»¶ (åŒºåŸŸç­‰çº§ã€å‘è¡Œå¹´ä»½Â±1Yã€æ˜¯å¦äº¤ç¨) æˆ–å°è¯•è°ƒæ•´ç›®æ ‡å±æ€§çš„è¾“å…¥å€¼ã€‚"
        )
        return
        
    config = TOLERANCE_LEVELS.get(relaxation_level)
    
    if relaxation_level == 0:
        st.success(f"âœ… ç›¸ä¼¼åˆ¸å·²é€šè¿‡ **{config['name']}** ç­›é€‰æ‰¾åˆ°ã€‚")
    elif relaxation_level == 1:
        st.warning(f"âš ï¸ ç›¸ä¼¼åˆ¸å·²é€šè¿‡ **{config['name']}** æ‰¾åˆ° (å·²æ”¾æ¾ä¸“é¡¹/ä¸€èˆ¬é™åˆ¶)ã€‚")
    elif relaxation_level == 2:
        st.error(f"ğŸ›‘ ç›¸ä¼¼åˆ¸å·²é€šè¿‡ **{config['name']}** æ‰¾åˆ° (å·²å¯ç”¨æœ€å¤§æ”¾æ¾é™åˆ¶)ã€‚")

    st.markdown(f"""
    **ä½¿ç”¨çš„ç­›é€‰å…¬å·®èŒƒå›´:**
    * **å‰©ä½™å¹´é™:** $\pm {config['term_tol']:.2f}$ å¹´
    * **ç¥¨é¢åˆ©ç‡:** $\pm {config['coupon_tol']:.2f}\%$
    * **ä¸“é¡¹/ä¸€èˆ¬åŒ¹é…:** {'æ˜¯ (ä¸¥æ ¼åŒ¹é…)' if config['type_match'] else 'å¦ (ä¸è¦æ±‚åŒ¹é…)'}
    * **å‘è¡Œå¹´ä»½:** $\pm 1$ å¹´ (å›ºå®š)
    * **åŒºåŸŸç­‰çº§/æ˜¯å¦äº¤ç¨:** å¿…é¡»ä¸¥æ ¼åŒ¹é… (å›ºå®š)
    """)
    
    # --- å®šä»·è¶‹åŠ¿å¯è§†åŒ–åˆ†æ (ä½¿ç”¨å…¨å¸‚åœºæœ€æ–°æ•°æ®) ---
    
    st.subheader("å…¨å¸‚åœºå®šä»·è¶‹åŠ¿å¯è§†åŒ–åˆ†æ (æœ€æ–°æ—¥æœŸï¼ŒæŒ‰åŒºåŸŸå’Œäº¤ç¨çŠ¶æ€åŒºåˆ†)")
    
    # æå–æœ€æ–°çš„æ—¥æœŸæ•°æ®ï¼Œç”¨äºç»˜åˆ¶èƒŒæ™¯å›¾
    latest_date = df['å½“å‰æ—¥æœŸ'].max()
    latest_date_df = df[df['å½“å‰æ—¥æœŸ'] == latest_date].copy()
    
    if latest_date_df.empty:
        st.warning("æ— æ³•æ‰¾åˆ°æœ€æ–°äº¤æ˜“æ—¥æœŸçš„å…¨å¸‚åœºæ•°æ®ï¼Œå›¾è¡¨æ— æ³•ç»˜åˆ¶ã€‚")
        return

    # å®šä¹‰é¢œè‰²æ˜ å°„ï¼šA(ç»¿), B(è“), C(çº¢)
    color_scale = alt.Scale(
        domain=['A', 'B', 'C'], 
        range=['green', 'blue', 'red']
    )
    
    # å®šä¹‰å½¢çŠ¶æ˜ å°„ï¼š'æ˜¯' -> ä¸‰è§’å½¢, 'å¦' -> åœ†å½¢ (æ›´é€šç”¨çš„å½¢çŠ¶)
    shape_map = {'æ˜¯': 'triangle', 'å¦': 'circle'}
    
    # æ•£ç‚¹å›¾ä½¿ç”¨ mark_point ä»¥ç¡®ä¿å½¢çŠ¶ç¼–ç å¯ä»¥æ­£ç¡®è¦†ç›–ï¼Œè€Œä¸æ˜¯è¢« mark_circle é™åˆ¶ä¸ºåœ†å½¢
    scatter = alt.Chart(latest_date_df).mark_point(size=60).encode( # <<< å…³é”®ä¿®æ­£ï¼šmark_point
        x=alt.X('å‰©ä½™å¹´é™', title='å‰©ä½™å¹´é™ (å¹´)', axis=alt.Axis(format='.2f')),
        y=alt.Y('æ”¶ç›˜æ”¶ç›Šç‡', title='æ”¶ç›˜æ”¶ç›Šç‡ (%)', axis=alt.Axis(format='.4f')),
        
        # åº”ç”¨å®šåˆ¶åŒ–çš„é¢œè‰²æ˜ å°„ (åŒºåŸŸç­‰çº§)
        color=alt.Color('åŒºåŸŸç­‰çº§', scale=color_scale, title='åŒºåŸŸç­‰çº§ (ç»¿/è“/çº¢)'),
        
        # åº”ç”¨å®šåˆ¶åŒ–çš„å½¢çŠ¶æ˜ å°„ (æ˜¯å¦äº¤ç¨)
        shape=alt.Shape('æ˜¯å¦äº¤ç¨', 
             scale=alt.Scale(domain=list(shape_map.keys()), range=list(shape_map.values())),
             title='æ˜¯å¦äº¤ç¨ (ä¸‰è§’/åœ†)'
        ),
        
        tooltip=['å€ºåˆ¸åç§°', alt.Tooltip('å‰©ä½™å¹´é™', format='.2f'), alt.Tooltip('æ”¶ç›˜æ”¶ç›Šç‡', format='.4f'), 'åŒºåŸŸç­‰çº§', 'æ˜¯å¦äº¤ç¨']
    ).properties(
        title=f'æœ€æ–°äº¤æ˜“æ—¥ ({latest_date.strftime("%Y-%m-%d")}) å¸‚åœºå®šä»·æ›²çº¿'
    ).interactive()

    # è¶‹åŠ¿çº¿ (çº¿æ€§å›å½’)
    regression_line = scatter.transform_regression('å‰©ä½™å¹´é™', 'æ”¶ç›˜æ”¶ç›Šç‡', method='linear').mark_line(color='gray', strokeDash=[3,3])

    # åˆå¹¶æ•£ç‚¹å›¾å’Œè¶‹åŠ¿çº¿
    chart = scatter + regression_line

    st.altair_chart(chart, use_container_width=True)
    
    # --- ç­›é€‰ç»“æœè¯¦æƒ…è¡¨æ ¼ (ä½¿ç”¨ç›¸ä¼¼åˆ¸ filtered_df) ---
    
    # ç»“æœæ’åºï¼šæŒ‰å‰©ä½™å¹´é™é™åº
    filtered_df = filtered_df.sort_values(by='å‰©ä½™å¹´é™', ascending=False)
    
    st.subheader("ç›¸ä¼¼åˆ¸ç­›é€‰ç»“æœè¯¦æƒ…")

    display_cols = [
        'å€ºåˆ¸ä»£ç ', 
        'å€ºåˆ¸åç§°', 
        'å‰©ä½™å¹´é™', 
        'å½“å‰æ—¥æœŸ',  
        'æ”¶ç›˜æ”¶ç›Šç‡', 
        'ä¼°å€¼', 
        'ç¥¨é¢', 
        'åŒºåŸŸ', 
        'åŒºåŸŸç­‰çº§',
        'ä¸“é¡¹ä¸€èˆ¬',
        'æ˜¯å¦äº¤ç¨',
        'ä½™é¢',
        'æˆäº¤é‡',
    ]
    
    st.dataframe(
        filtered_df[display_cols].style.format({
            'å‰©ä½™å¹´é™': "{:.2f} å¹´",
            'æ”¶ç›˜æ”¶ç›Šç‡': "{:.4f}%",
            'ä¼°å€¼': "{:.4f}%",
            'ç¥¨é¢': "{:.2f}%",
            'ä½™é¢': "{:,.2f}",
            'æˆäº¤é‡': "{:,.0f}",
            'å½“å‰æ—¥æœŸ': lambda t: t.strftime('%Y-%m-%d') if pd.notna(t) and not pd.isna(t) else ''
        }),
        width='stretch'
    )
    
    st.markdown("---")
    st.caption(f"**ç›®æ ‡åˆ¸ä¿¡æ¯ï¼š** å‰©ä½™å¹´é™ {target_attributes['term']:.2f}å¹´ | ç¥¨é¢ {target_attributes['coupon']:.2f}% | åŒºåŸŸç­‰çº§ {region_level}")

if __name__ == '__main__':
    main()